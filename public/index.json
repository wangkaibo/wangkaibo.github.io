[{"content":"","date":null,"permalink":"/","section":"Congo","summary":"","title":"Congo"},{"content":"","date":null,"permalink":"/post/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"判断是否存在环 #定义两个指针 p1，p2，从head节点开始遍历，每次循环p1向前移一位，p2向前移两位，若链表存在环则p1，p2必然有相等的时候。\nfunction hasCycle($linkedList) { $p1 = $p2 = $linkedList-\u0026gt;headNode; while ($p1-\u0026gt;nextNode) { $p1 = $p1-\u0026gt;nextNode; $p2 = $p2-\u0026gt;nextNode-\u0026gt;nextNode; if ($p1 == $p2) { return true; } } return false; } 找出环的位置 # 假设 p1 经过的路程是 S，因为 p2 速度是 p1 的 2 倍，所以 p2 经过的路程为2S\n假设 p2 比 p1 多走n圈的距离才到达汇合点，那么可以得出：\n$2S = S + NR$ 即$S=NR$\n代入 $2S = A+ X + NR$\n得出 $NR = A + X$\n又 $R=X+T$\n代入得\n$NR=A+R-T$$ 即 $$A=(N-1)R+T$\n根据上述推导的公式可以得出结论：从汇合点和起点的两个指针定会在环的交点相遇！\n代码来了\nfunction getCycleNode($linkedList) { $p1 = $p2 = $linkedList-\u0026gt;headNode; while($p1-\u0026gt;nextNode) { $p1 = $p1-\u0026gt;nextNode; $p2 = $p2-\u0026gt;nextNode-\u0026gt;nextNode; if ($p1 == $p2) { break; } } if (!$p1) { return false; } $p3 = $linkedList-\u0026gt;headNode; while($p1 != $p3) { $p1 = $p1-\u0026gt;nextNode; $p3 = $p3-\u0026gt;nextNode; } return p1; } ","date":"21 January 2018","permalink":"/linked-list-cycle/","section":"Posts","summary":"判断是否存在环 #定义两个指针 p1，p2，从head节点开始遍历，每次循环p1向前移一位，p2向前移两位，若链表存在环则p1，p2必然有相等的时候。","title":"单向链表环问题"},{"content":"友情链接 #吴钧泽博客\n","date":"21 January 2018","permalink":"/links/","section":"Congo","summary":"友情链接 #吴钧泽博客","title":"友情链接"},{"content":"","date":null,"permalink":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","section":"Tags","summary":"","title":"数据结构"},{"content":"","date":null,"permalink":"/tags/%E7%AE%97%E6%B3%95/","section":"Tags","summary":"","title":"算法"},{"content":"什么情况下需要布隆过滤器？ #先来看几个比较常见的例子\n字处理软件中，需要检查一个英语单词是否拼写正确 在 FBI，一个嫌疑人的名字是否已经在嫌疑名单上 在网络爬虫里，一个网址是否被访问过 yahoo, gmail等邮箱垃圾邮件过滤功能 这几个例子有一个共同的特点： 如何判断一个元素是否存在一个集合中？\n常规思路 # 数组 链表 树、平衡二叉树、Trie Map (红黑树) 哈希表 虽然上面描述的这几种数据结构配合常见的排序、二分搜索可以快速高效的处理绝大部分判断元素是否存在集合中的需求。但是当集合里面的元素数量足够大，如果有500万条记录甚至1亿条记录呢？这个时候常规的数据结构的问题就凸显出来了。数组、链表、树等数据结构会存储元素的内容，一旦数据量过大，消耗的内存也会呈现线性增长，最终达到瓶颈。有的同学可能会问，哈希表不是效率很高吗？查询效率可以达到O(1)。但是哈希表需要消耗的内存依然很高。使用哈希表存储一亿 个垃圾 email 地址的消耗？哈希表的做法：首先，哈希函数将一个email地址映射成8字节信息指纹；考虑到哈希表存储效率通常小于50%（哈希冲突）；因此消耗的内存：8 * 2 * 1亿 字节 = 1.6G 内存，普通计算机是无法提供如此大的内存。这个时候，布隆过滤器（Bloom Filter）就应运而生。在继续介绍布隆过滤器的原理时，先讲解下关于哈希函数的预备知识。\n哈希函数 #哈希函数的概念是：将任意大小的数据转换成特定大小的数据的函数，转换后的数据称为哈希值或哈希编码。下面是一幅示意图：\n可以明显的看到，原始数据经过哈希函数的映射后称为了一个个的哈希编码，数据得到压缩。哈希函数是实现哈希表和布隆过滤器的基础。\n布隆过滤器介绍 # 巴顿.布隆于一九七零年提出 一个很长的二进制向量 （位数组） 一系列随机函数 (哈希) 空间效率和查询效率高 有一定的误判率（哈希表是精确匹配） 布隆过滤器原理 #布隆过滤器（Bloom Filter）的核心实现是一个超大的位数组和几个哈希函数。假设位数组的长度为m，哈希函数的个数为k\n以上图为例，具体的操作流程：假设集合里面有3个元素{x, y, z}，哈希函数的个数为3。首先将位数组进行初始化，将里面每个位都设置位0。对于集合里面的每一个元素，将元素依次通过3个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。查询W元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。反之，如果3个点都为1，则该元素可能存在集合中。注意：此处不能判断该元素是否一定存在集合中，可能存在一定的误判率。可以从图中可以看到：假设某个元素通过映射对应下标为4，5，6这3个点。虽然这3个点都为1，但是很明显这3个点是不同元素经过哈希得到的位置，因此这种情况说明元素虽然不在集合中，也可能对应的都是1，这是误判率存在的原因。\n布隆过滤器添加元素 # 将要添加的元素给k个哈希函数 得到对应于位数组上的k个位置 将这k个位置设为1 布隆过滤器查询元素 # 将要查询的元素给k个哈希函数 得到对应于位数组上的k个位置 如果k个位置有一个为0，则肯定不在集合中 如果k个位置全部为1，则可能在集合中 布隆过滤器实现 #下面给出python的实现，使用murmurhash算法\nimport mmh3 from bitarray import bitarray # zhihu_crawler.bloom_filter # Implement a simple bloom filter with murmurhash algorithm. # Bloom filter is used to check wether an element exists in a collection, and it has a good performance in big data situation. # It may has positive rate depend on hash functions and elements count. BIT_SIZE = 5000000 class BloomFilter: def __init__(self): # Initialize bloom filter, set size and all bits to 0 bit_array = bitarray(BIT_SIZE) bit_array.setall(0) self.bit_array = bit_array def add(self, url): # Add a url, and set points in bitarray to 1 (Points count is equal to hash funcs count.) # Here use 7 hash functions. point_list = self.get_postions(url) for b in point_list: self.bit_array[b] = 1 def contains(self, url): # Check if a url is in a collection point_list = self.get_postions(url) result = True for b in point_list: result = result and self.bit_array[b] return result def get_postions(self, url): # Get points positions in bit vector. point1 = mmh3.hash(url, 41) % BIT_SIZE point2 = mmh3.hash(url, 42) % BIT_SIZE point3 = mmh3.hash(url, 43) % BIT_SIZE point4 = mmh3.hash(url, 44) % BIT_SIZE point5 = mmh3.hash(url, 45) % BIT_SIZE point6 = mmh3.hash(url, 46) % BIT_SIZE point7 = mmh3.hash(url, 47) % BIT_SIZE return [point1, point2, point3, point4, point5, point6, point7] 原文地址：布隆过滤器的原理和实现\n相关文章：基于Redis的布隆过滤器的实现\n","date":"22 December 2017","permalink":"/bu-long-guo-lv-qi-yuan-li-shi-xian/","section":"Posts","summary":"\u003ch3 id=\"什么情况下需要布隆过滤器\" class=\"relative group\"\u003e什么情况下需要布隆过滤器？ \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e4%bb%80%e4%b9%88%e6%83%85%e5%86%b5%e4%b8%8b%e9%9c%80%e8%a6%81%e5%b8%83%e9%9a%86%e8%bf%87%e6%bb%a4%e5%99%a8\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cp\u003e先来看几个比较常见的例子\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e字处理软件中，需要检查一个英语单词是否拼写正确\u003c/li\u003e\n\u003cli\u003e在 FBI，一个嫌疑人的名字是否已经在嫌疑名单上\u003c/li\u003e\n\u003cli\u003e在网络爬虫里，一个网址是否被访问过\u003c/li\u003e\n\u003cli\u003eyahoo, gmail等邮箱垃圾邮件过滤功能\u003c/li\u003e\n\u003c/ul\u003e","title":"【转载】布隆过滤器的原理和实现"},{"content":"方法介绍 #对于海量数据而言，由于无法一次性装进内存处理，导致我们不得不把海量的数据通过hash映射分割成相应的小块数据，然后再针对各个小块数据通过hash_map进行统计或其它操作。\n那什么是hash映射呢？简单来说，就是为了便于计算机在有限的内存中处理big数据，我们通过一种映射散列的方式让数据均匀分布在对应的内存位置(如大数据通过取余的方式映射成小数存放在内存中，或大文件映射成多个小文件)，而这个映射散列方式便是我们通常所说的hash函数，设计的好的hash函数能让数据均匀分布而减少冲突。\n问题实例 #1、海量日志数据，提取出某日访问百度次数最多的那个IP\n分析：百度作为国内第一大搜索引擎，每天访问它的IP数量巨大，如果想一次性把所有IP数据装进内存处理，则内存容量明显不够，故针对数据太大，内存受限的情况，可以把大文件转化成（取模映射）小文件，从而大而化小，逐个处理。\n换言之，先映射，而后统计，最后排序。\n解法：具体分为以下3个步骤\n1.分而治之/hash映射 首先把这一天访问百度日志的所有IP提取出来，然后逐个写入到一个大文件中，接着采用映射的方法，比如%1000，把整个大文件映射为1000个小文件。 2.hash_map统计 当大文件转化成了小文件，那么我们便可以采用hash_map(ip, value)来分别对1000个小文件中的IP进行频率统计，再找出每个小文件中出现频率最大的IP。 3.堆/快速排序 统计出1000个频率最大的IP后，依据各自频率的大小进行排序(可采取堆排序)，找出那个频率最大的IP，即为所求。 注：Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中去的情况，即这里采用的是%1000算法，那么同一个IP在hash后，只可能落在同一个文件中，不可能被分散的。\n2、寻找热门查询，300万个查询字符串中统计最热门的10个查询\n原题：搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，请你统计最热门的10个查询串，要求使用的内存不能超过1G。\n分析：这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。\n由上面第1题，我们知道，数据大则划为小的，例如一亿个ip求Top 10，可先%1000将ip分到1000个小文件中去，并保证一种ip只出现在一个文件中，再对每个小文件中的ip进行hash_map统计并按数量排序，最后归并或者最小堆依次处理每个小文件的top10以得到最后的结果。\n但对于本题，数据规模比较小，能一次性装入内存。因为根据题目描述，虽然有一千万个Query，但是由于重复度比较高，故去除重复后，事实上只有300万的Query，每个Query255Byte，因此我们可以考虑把他们都放进内存中去（300万个字符串假设没有重复，都是最大长度，那么最多占用内存3M*1K/4=0.75G。所以可以将所有字符串都存放在内存中进行处理）。\n所以我们放弃分而治之/hash映射的步骤，直接上hash_map统计，然后排序。So，针对此类典型的TOP K问题，采取的对策往往是：hash_map + 堆。\n解法：\n1.hash_map统计 先对这批海量数据预处理。具体方法是：维护一个Key为Query字串，Value为该Query出现次数的hash_map，即hash_map(Query, Value)，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并将Value值设为1；如果该字串在Table中，那么将该字串的计数加1 即可。最终我们在O(N)的时间复杂度内用hash_map完成了统计； 2.堆排序 借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。即借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。所以，我们最终的时间复杂度是：O(n) + N\u0026rsquo; * O(logk），其中，N为1000万，N’为300万。 关于第2步堆排序，可以维护k个元素的最小堆，即用容量为k的最小堆存储最先遍历到的k个数，并假设它们即是最大的k个数，建堆费时O（k），并调整堆(费时O(logk))后，有k1\u0026gt;k2\u0026gt;\u0026hellip;kmin（kmin设为小顶堆中最小元素）。继续遍历数列，每次遍历一个元素x，与堆顶元素比较，若x\u0026gt;kmin，则更新堆（x入堆，用时logk），否则不更新堆。这样下来，总费时O（k*logk+（n-k）logk）=O（nlogk）。此方法得益于在堆中，查找等各项操作时间复杂度均为logk。\n当然，你也可以采用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。\n3、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词\n解法：\n1.分而治之/hash映射 顺序读取文件，对于每个词x，取hash(x)%5000，然后把该值存到5000个小文件（记为x0,x1,\u0026hellip;x4999）中。这样每个文件大概是200k左右。当然，如果其中有的小文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。 2.hash_map统计 对每个小文件，采用trie树/hash_map等统计每个文件中出现的词以及相应的频率。 3.堆/归并排序 取出出现频率最大的100个词（可以用含100个结点的最小堆）后，再把100个词及相应的频率存入文件，这样又得到了5000个文件。最后就是把这5000个文件进行归并（类似于归并排序）的过程了。 4、海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10\n解法一：\n如果同一个数据元素只出现在某一台机器中，那么可以采取以下步骤统计出现次数TOP10的数据元素：\n1.堆排序 在每台电脑上求出TOP 10，可以采用包含10个元素的堆完成（TOP 10小，用最大堆，TOP 10大，用最小堆，比如求TOP10大，我们首先取前10个元素调整成最小堆，如果发现，然后扫描后面的数据，并与堆顶元素比较，如果比堆顶元素大，那么用该元素替换堆顶，然后再调整为最小堆。最后堆中的元素就是TOP 10大）。 2.组合归并 求出每台电脑上的TOP 10后，然后把这100台电脑上的TOP 10组合起来，共1000个数据，再利用上面类似的方法求出TOP 10就可以了。 解法二：\n但如果同一个元素重复出现在不同的电脑中呢，比如拿两台机器求top 2的情况来说：\n第一台的数据分布及各自出现频率为：a(50)，b(50)，c(49)，d(49) ，e(0)，f(0) 其中，括号里的数字代表某个数据出现的频率，如a(50)表示a出现了50次。 第二台的数据分布及各自出现频率为：a(0)，b(0)，c(49)，d(49)，e(50)，f(50) 这个时候，你可以有两种方法：\n遍历一遍所有数据，重新hash取摸，如此使得同一个元素只出现在单独的一台电脑中，然后采用上面所说的方法，统计每台电脑中各个元素的出现次数找出TOP 10，继而组合100台电脑上的TOP 10，找出最终的TOP 10。 或者，暴力求解：直接统计统计每台电脑中各个元素的出现次数，然后把同一个元素在不同机器中的出现次数相加，最终从所有数据中找出TOP 10。 5、有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序\n解法一：\n1.hash映射 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件（记为a0,a1,..a9）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。 2.hash_map统计 找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。注：hash_map(query, query_count)是用来统计每个query的出现次数，不是存储他们的值，出现一次，则count+1。 3.堆/快速/归并排序 利用快速/堆/归并排序按照出现次数进行排序，将排序好的query和对应的query_cout输出到文件中，这样得到了10个排好序的文件（记为 ）。最后，对这10个文件进行归并排序（内排序与外排序相结合）。 解法二：\n一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树/hash_map等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并排序就可以了。\n解法三：\n与解法1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。\n6、给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？\n解法：\n可以估计每个文件安的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。\n1.分而治之/hash映射 遍历文件a，对每个url求取 ，然后根据所取得的值将url分别存储到1000个小文件（记为 ，这里漏写个了a1）中。这样每个小文件的大约为300M。遍历文件b，采取和a相同的方式将url分别存储到1000小文件中（记为 ）。这样处理后，所有可能相同的url都在对应的小文件（ ）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。 2.hash_set统计 求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。 7、100万个数中找出最大的100个数\n解法一：采用局部淘汰法。选取前100个元素，并排序，记为序列L。然后一次扫描剩余的元素x，与排好序的100个元素中最小的元素比，如果比这个最小的要大，那么把这个最小的元素删除，并把x利用插入排序的思想，插入到序列L中。依次循环，知道扫描了所有的元素。复杂度为O(100万*100)。\n解法二：采用快速排序的思想，每次分割之后只考虑比主元大的一部分，直到比主元大的一部分比100多的时候，采用传统排序算法排序，取前100个。复杂度为O(100万*100)。\n解法三：在前面的题中，我们已经提到了，用一个含100个元素的最小堆完成。复杂度为O(100万*lg100)。\n举一反三 #1、怎么在海量数据中找出重复次数最多的一个？\n提示：先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。然后找出上一步求出的数据中重复次数最多的一个就是所求（具体参考前面的题）。\n2、上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。\n提示：上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map/搜索二叉树/红黑树等来进行统计次数。然后就是取出前N个出现次数最多的数据了，可以用第2题提到的堆机制完成。\n3、一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。\n提示：这题是考虑时间效率。用trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度）。然后是找出出现最频繁的前10个词，可以用堆来实现，前面的题中已经讲到了，时间复杂度是O(n*lg10)。所以总的时间复杂度，是O(n*le)与O(n*lg10)中较大的哪一个。\n4、1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？\n提示：这题用trie树比较合适，hash_map也行。当然，也可以先hash成小文件分开处理再综合。\n5、一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。\n提示：首先根据用hash并求模，将文件分解为多个小文件，对于单个文件利用上题的方法求出每个文件件中10个最常出现的词。然后再进行归并处理，找出最终的10个最常出现的词。\n原文地址：编程之法：面试和算法心得-分而治之\n","date":"16 December 2017","permalink":"/hai-liang-shu-ju-chu-li-fen-er-zhi-zhi/","section":"Posts","summary":"\u003ch3 id=\"方法介绍\" class=\"relative group\"\u003e方法介绍 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e6%96%b9%e6%b3%95%e4%bb%8b%e7%bb%8d\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cp\u003e对于海量数据而言，由于无法一次性装进内存处理，导致我们不得不把海量的数据通过hash映射分割成相应的小块数据，然后再针对各个小块数据通过hash_map进行统计或其它操作。\u003c/p\u003e","title":"【转载】海量数据处理之「分而治之」"},{"content":"","date":null,"permalink":"/tags/tcp/","section":"Tags","summary":"","title":"Tcp"},{"content":"最近在补充HTTP/TCP协议的一些知识。看到《HTTP权威指南》中TCP连接时觉得下图描述的比之前看其他人写的博文要清楚的多。\n图：TCP客户端和服务器是如何通过TCP套接字进行通信的\n在发送数据前，TCP要穿送两个分组来建立连接，也就是传说中的三次握手。\n第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；\n第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；\n第三次握手：客户端收到服务器的SYN＋ACK包，验证ack=j+1，并向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。完成三次握手，客户端与服务器开始传送数据。\n","date":"16 November 2017","permalink":"/tcp-client-server-connection/","section":"Posts","summary":"\u003cp\u003e最近在补充HTTP/TCP协议的一些知识。看到《HTTP权威指南》中TCP连接时觉得下图描述的比之前看其他人写的博文要清楚的多。\u003c/p\u003e","title":"TCP客户端和服务器是如何通过TCP套接字进行通信的"},{"content":"","date":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux"},{"content":"","date":null,"permalink":"/tags/lnmp/","section":"Tags","summary":"","title":"LNMP"},{"content":"今天看 PHP 官网 7.1.3 的稳定版已经出来了，准备尝尝鲜，安装过程没有什么变化，这里只是简单记录下。\n安装 nginx 1.8 #添加官方 yum 源 #nginx 提供了官方的 yum 源，安装 nginx 的 1.8 可以使用官方的 yum 源，速度还不错。\n在 /etc/yum.repo.d/ 下新建文件 nginx.repo\n[nginx] name=nginx repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=0 enabled=1 ubuntu/debian 源具体参见：官方文档\n安装 nginx #使用 yum install nginx 安装，yum 会查找软件包和依赖然后提示是否安装，看好版本后，选择 Y。\n/etc/init.d/nginx start 可以使用 curl localhost 验证 nginx 是否安装成功。\n安装 PHP7 #注意：如果没有安装 MySQL 的话，最好先安装一下 MySQL。\n安装依赖 #yum install -y libxml2 libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers php-mysqlnd libmcrypt-devel libtidy libtidy-devel recode recode-devel libxpm-devel libXpm-devel 安装 libmcrypt：\nwget ftp://mcrypt.hellug.gr/pub/crypto/mcrypt/libmcrypt/libmcrypt-2.5.6.tar.gz tar -zxvf libmcrypt-2.5.6.tar.gz cd libmcrypt-2.5.6.tar. make \u0026amp;\u0026amp; make install 默认会安装在 /usr/local 目录下。\n下载 PHP 源码包 #我这里是安装的官方最新稳定版 PHP7.1.3，所以将使用源码安装方式安装。\nwget http://cn.php.net/distributions/php-7.1.3.tar.gz tar -xzvf php-7.1.3.tar.gz cd php-7.1.3 编译配置（当前应该在 php-7.1.3 目录下）：\n./configure --prefix=/usr/local/php --with-fpm-user=nginx --with-fpm-group=nginx --with-config-file-path=/etc/php --with-mysql=mysqlnd --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-gd --with-iconv --with-zlib --enable-xml --enable-bcmath --enable-shmop --enable-sysvsem --enable-inline-optimization --enable-mbregex --enable-fpm --enable-mbstring --enable-ftp --enable-gd-native-ttf --with-openssl --enable-pcntl --enable-sockets --with-xmlrpc --enable-zip --enable-soap --without-pear --with-gettext --enable-session --with-mcrypt --with-curl --with-jpeg-dir --with-freetype-dir --with-xpm-dir=/usr --with-bz2 编译：\nmake 这里可能会等挺长时间，安装过程大概就是复制编译后的文件的一个过程。\nmake test \u0026amp; make install 这里需要注意一下，前面 configure 时我们配置了 php.ini 的路径为 /etc/php，然而发现并没有这个目录也找不到 php.ini 文件。没关系，这里可以手动的复制一个配置文件过去，配置文件可以在源码包 php-7.1.3 里找到，它包括了开发环境和生产环境的默认配置。\n#开发环境 cp ~/php-7.1.3/php.ini-development ./php.ini #生产环境 cp ~/php-7.1.3/php.ini-production ./php.ini 配置 nginx #修改 /etc/nginx/conf.d/default.conf 文件\n... location / { root /var/www; index index.html index.htmi index.php; } ... # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ .php$ { # 根目录 root root /var/www; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 配置 php-fpm #cp /local/php/etc/php-fpm.conf.default /local/php/etc/php-fpm.conf cp /local/php/etc/php-fpm.d/www.conf.default /local/php/etc/php-fpm.d/www.conf 为了更方便的启动 php-fpm，我们为它添加 sysv 风格的初始化服务脚本，nginx 是通过 yum 安装的是有 /etc/init.d/nginx 这个启动脚本的。\n新建文件 /etc/init.d/php-fpm：\n#!/bin/bash # # Startup script for the PHP-FPM server. # # chkconfig: 345 85 15 # description: PHP is an HTML-embedded scripting language # processname: php-fpm # config: /usr/local/php/etc/php.ini # Source function library. . /etc/rc.d/init.d/functions PHP_PATH=/usr/local DESC=\u0026#34;php-fpm daemon\u0026#34; NAME=php-fpm # php-fpm路径 DAEMON=$PHP_PATH/php/sbin/$NAME # 配置文件路径 CONFIGFILE=$PHP_PATH/php/etc/php-fpm.conf # PID文件路径不清楚可以查看 /usr/local/php/etc/php-fpm.conf PIDFILE=$PHP_PATH/php/var/run/$NAME.pid SCRIPTNAME=/etc/init.d/$NAME # Gracefully exit if the package has been removed. test -x $DAEMON || exit 0 rh_start() { $DAEMON -y $CONFIGFILE || echo -n \u0026#34; already running\u0026#34; } rh_stop() { kill -QUIT `cat $PIDFILE` || echo -n \u0026#34; not running\u0026#34; } rh_reload() { kill -HUP `cat $PIDFILE` || echo -n \u0026#34; can\u0026#39;t reload\u0026#34; } case \u0026#34;$1\u0026#34; in start) echo -n \u0026#34;Starting $DESC: $NAME\u0026#34; rh_start echo \u0026#34;.\u0026#34; ;; stop) echo -n \u0026#34;Stopping $DESC: $NAME\u0026#34; rh_stop echo \u0026#34;.\u0026#34; ;; reload) echo -n \u0026#34;Reloading $DESC configuration...\u0026#34; rh_reload echo \u0026#34;reloaded.\u0026#34; ;; restart) echo -n \u0026#34;Restarting $DESC: $NAME\u0026#34; rh_stop sleep 1 rh_start echo \u0026#34;.\u0026#34; ;; *) echo \u0026#34;Usage: $SCRIPTNAME {start|stop|restart|reload}\u0026#34; \u0026gt;\u0026amp;2 exit 3 ;; esac exit 0 # 赋予执行权限 sudo chmod +x /etc/init.d/php-fpm # 修改启动等级 sudo /sbin/chkconfig php-fpm on 下面就可以用以下命令控制 php-fpm 了\n/etc/init.d/php-fpm start /etc/init.d/php-fpm stop /etc/init.d/php-fpm restart /etc/init.d/php-fpm reload 启动 php-fpm 后就可测试一下 PHP 文件能否执行了。\n有问题可留言\n参考资料 #nginx 文档\nNginx和PHP-FPM的启动/重启脚本\n","date":"8 October 2017","permalink":"/centos-6-8-install-nginx-stable-and-php7/","section":"Posts","summary":"\u003cp\u003e今天看 PHP 官网 7.1.3 的稳定版已经出来了，准备尝尝鲜，安装过程没有什么变化，这里只是简单记录下。\u003c/p\u003e","title":"日常折腾环境😂Nginx + PHP 7.1.3"},{"content":"","date":null,"permalink":"/tags/pwa/","section":"Tags","summary":"","title":"PWA"},{"content":"Ghost 博客支持 Progressive Web Apps （PWA） #一直对 Google 的 Progressive Web Apps （以下简称 PWA） 有点兴趣，所以拿我的博客做实验，让 Ghost 博客支持 PWA。\nPS：如果你的博客还不支持 https 的话，那么也就不支持 Service Worker，也就是说实现不了 Progressive Web Apps。\n如果对 PWA 不是很了解，建议先阅读：\n你的首个Progressive Web App [English] [中文] 下一代 Web 应用模型 —— Progressive Web App Service worker 概念和用法 Service Worker Tools 添加 Service Worker Toolbox #在主题目录下（默认为 ghost/content/themes/casper）的 assets 新建 dist 目录。\n在该目录添加 sw-toolbox.js 文件，文件内容在这里\n###添加缓存脚本\n在您的主题根目录下创建名为serviceworker-v1.js的文件，这里需要注意 serviceworker-v1.js 这个文件一定要放到网站根目录，因为它的位置也指定了 Service Worker 可执行的目录权限。\n在该文件中包含以下代码：\n\u0026#39;use strict\u0026#39;; (function () { \u0026#39;use strict\u0026#39;; /** * Service Worker Toolbox caching */ var cacheVersion = \u0026#39;-toolbox-v1\u0026#39;; var dynamicVendorCacheName = \u0026#39;dynamic-vendor\u0026#39; + cacheVersion; var staticVendorCacheName = \u0026#39;static-vendor\u0026#39; + cacheVersion; var staticAssetsCacheName = \u0026#39;static-assets\u0026#39; + cacheVersion; var contentCacheName = \u0026#39;content\u0026#39; + cacheVersion; var maxEntries = 50; self.importScripts(\u0026#39;assets/dist/sw-toolbox.js\u0026#39;); self.toolbox.options.debug = false; // Cache own static assets self.toolbox.router.get(\u0026#39;/assets/(.*)\u0026#39;, self.toolbox.cacheFirst, { cache: { name: staticAssetsCacheName, maxEntries: maxEntries } }); // cache dynamic vendor assets, things which have no other update mechanism like filename change/version hash self.toolbox.router.get(\u0026#39;/css\u0026#39;, self.toolbox.fastest, { origin: /fonts\\.googleapis\\.com/, cache: { name: dynamicVendorCacheName, maxEntries: maxEntries } }); // Do not cache disqus self.toolbox.router.get(\u0026#39;/(.*)\u0026#39;, self.toolbox.networkOnly, { origin: /disqus\\.com/ }); self.toolbox.router.get(\u0026#39;/(.*)\u0026#39;, self.toolbox.networkOnly, { origin: /disquscdn\\.com/ }); // Cache all static vendor assets, e.g. fonts whose version is bind to the according url self.toolbox.router.get(\u0026#39;/(.*)\u0026#39;, self.toolbox.cacheFirst, { origin: /(fonts\\.gstatic\\.com|www\\.google-analytics\\.com)/, cache: { name: staticVendorCacheName, maxEntries: maxEntries } }); self.toolbox.router.get(\u0026#39;/content/(.*)\u0026#39;, self.toolbox.fastest, { cache: { name: contentCacheName, maxEntries: maxEntries } }); self.toolbox.router.get(\u0026#39;/*\u0026#39;, function (request, values, options) { if (!request.url.match(/(\\/ghost\\/|\\/page\\/)/) \u0026amp;\u0026amp; request.headers.get(\u0026#39;accept\u0026#39;).includes(\u0026#39;text/html\u0026#39;)) { return self.toolbox.fastest(request, values, options); } else { return self.toolbox.networkOnly(request, values, options); } }, { cache: { name: contentCacheName, maxEntries: maxEntries } }); // immediately activate this serviceworker self.addEventListener(\u0026#39;install\u0026#39;, function (event) { return event.waitUntil(self.skipWaiting()); }); self.addEventListener(\u0026#39;activate\u0026#39;, function (event) { return event.waitUntil(self.clients.claim()); }); })(); //# sourceMappingURL=serviceworker-v1.js.map 如果在部署阶段，可以将上段代码中的 self.toolbox.options.debug 改为 true。\n从下面这段代码可以看出 service worker 使用 Express 路由的代码风格来定位指定的资源：\n// 缓存静态资源 self.toolbox.router.get(\u0026#39;/assets/(.*)\u0026#39;, self.toolbox.cacheFirst, { cache: { name: staticAssetsCacheName, maxEntries: maxEntries } }); 有以下几种获取资源的方式：\ncacheFirst（缓存优先）： 如果请求与缓存条目匹配，则回应。 否则尝试从网络中获取资源。 如果网络请求成功，请更新缓存。 此选项适用于不更改的资源，或具有其他更新机制。 cacheFirst（最快）：从缓存和网络并行请求资源。以首先回报的方式作出回应。通常这将是缓存的版本，如果有的话。一方面，即使资源被缓存，这个策略总是会产生一个网络请求。另一方面，如果/当网络请求完成时，缓存被更新，以便将来的高速缓存读取将是更新的。 networkFirst（网络优先）：尝试通过从网络中提取来处理请求。如果成功，将响应存储在缓存中。 否则，尝试从缓存中完成请求。这是用于基本的直读缓存的策略。它也适用于API请求，当您始终希望最新数据可用时，而不是没有数据的陈旧数据。 cacheOnly：只使用缓存资源 networkOnly：只使用网络资源 如果我们不想缓存评论内容，我这里使用的是网易云跟帖，可以指定来自 163.com 和 netease.com 的文件的请求始终为网络：\n// Do not cache 163.com and netease.com self.toolbox.router.get(\u0026#39;/(.*)\u0026#39;, self.toolbox.networkOnly, { origin: /163\\.com/ }); self.toolbox.router.get(\u0026#39;/(.*)\u0026#39;, self.toolbox.networkOnly, { origin: /netease\\.com/ }); 缓存 Google fonts 和 Google Analytics:\n// Cache all static vendor assets, e.g. fonts whose version is bind to the according url self.toolbox.router.get(\u0026#39;/(.*)\u0026#39;, self.toolbox.cacheFirst, { origin: /(fonts\\.gstatic\\.com|www\\.google-analytics\\.com)/, cache: { name: staticVendorCacheName, maxEntries: maxEntries } }); 激活 Service Worker #只需通过 script 标签将下面的 JavaScript 代码引入到 defalut.hbs 即可：\nvar serviceWorkerUri = \u0026#39;/serviceworker-v1.js\u0026#39;; if (\u0026#39;serviceWorker\u0026#39; in navigator) { navigator.serviceWorker.register(serviceWorkerUri).then(function() { // Registration was successful. Now, check to see whether the service worker is controlling the page. if (navigator.serviceWorker.controller) { console.log(\u0026#39;Assets cached by the controlling service worker.\u0026#39;); } else { console.log(\u0026#39;Please reload this page to allow the service worker to handle network operations.\u0026#39;); } }).catch(function(error) { console.log(\u0026#39;ERROR: \u0026#39; + error); }); } else { // The current browser doesn\u0026#39;t support service workers. console.log(\u0026#39;Service workers are not supported in the current browser.\u0026#39;); } 可以打开开发者工具查看 Service Worker 的运行状况，在 Application 一栏中有 Service Worker 的选项卡。如果出现错误可以通过它进行调试。\n添加到主屏幕 #Progressive Web Apps 的官方文档指出，开发者需要提供一个 manifest.json 文件，这里我放在了网站根目录，它包含以下内容：\n{ \u0026#34;short_name\u0026#34;: \u0026#34;Pavel\u0026#39;s Blog\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Pavel\u0026#39;s Blog\u0026#34;, \u0026#34;icons\u0026#34;: [ { \u0026#34;src\u0026#34;: \u0026#34;assets/images/android-icon-144x144.png\u0026#34;, \u0026#34;sizes\u0026#34;: \u0026#34;144x144\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;image/png\u0026#34;, \u0026#34;density\u0026#34;: \u0026#34;3.0\u0026#34; } ], \u0026#34;start_url\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;display\u0026#34;: \u0026#34;standalone\u0026#34;, \u0026#34;orientation\u0026#34;: \u0026#34;portrait\u0026#34;, \u0026#34;background_color\u0026#34;: \u0026#34;#6595b8\u0026#34; } 在 default.hbs 中添加以下代码：\n\u0026lt;link rel=\u0026#34;manifest\u0026#34; href=\u0026#34;/manifest.json\u0026#34;\u0026gt; 下面在 Android Chrome 中打开你的博客，点右上角按钮——\u0026gt;添加到主屏幕，就可以看到类似原生 App 的效果了。\n有任何问题可以在下方评论讨论。\n参考资料 #Node, Ghost, and Progressive Web Apps (PWA)\n","date":"30 September 2017","permalink":"/node-express-ghost-progressive-web-apps-pwa/","section":"Posts","summary":"\u003ch3 id=\"ghost-博客支持-progressive-web-apps-pwa\" class=\"relative group\"\u003eGhost 博客支持 Progressive Web Apps （PWA） \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#ghost-%e5%8d%9a%e5%ae%a2%e6%94%af%e6%8c%81-progressive-web-apps-pwa\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cp\u003e一直对 Google 的 Progressive Web Apps （以下简称 PWA） 有点兴趣，所以拿我的博客做实验，让 Ghost 博客支持 PWA。\u003c/p\u003e\n\u003cp\u003ePS：如果你的博客还不支持 https 的话，那么也就不支持 Service Worker，也就是说实现不了 Progressive Web Apps。\u003c/p\u003e","title":"让你的Ghost博客支持Progressive Web Apps (PWA)"},{"content":"","date":null,"permalink":"/tags/php/","section":"Tags","summary":"","title":"Php"},{"content":"PHP session 获取不到之前设置值的问题 #今天帮朋友的服务器部署一个小程序商城时遇到一个 session 无法保存的问题。\n在 web 的一个页面通过 $_SESSION 设置的 session 值：\n$_SESSION[\u0026#39;user\u0026#39;] = \u0026#39;user\u0026#39;; var_dump($_SESSION); 设置完之后是可以打印出值的。但是跳转到另一页面却取不到 session 的值。\n虽然session.auto_start 配置为 Off，但已经排除了 session_start(); 没调用的问题。也没有通过 session_set_save_handler() 去自定义 session 的存储过程。\n通过 phpinfo函数给出的信息，看到了 session.save_path 配置是 /var/lib/php/session，进去该目录发现并没有任何文件。看到这里定位到应该是 session 目录权限问题。\n安装完 php-fpm ，默认运行用户是 apache，我之前改成了 nobody ，session 目录忘了改（这里应该极其容易忘）。😂\n这里把session目录权限改下就好了。环境问题有时候真的是防不胜防啊😂\n","date":"5 May 2017","permalink":"/php-session-%E8%8E%B7%E5%8F%96%E4%B8%8D%E5%88%B0/","section":"Posts","summary":"\u003ch3 id=\"php-session-获取不到之前设置值的问题\" class=\"relative group\"\u003ePHP session 获取不到之前设置值的问题 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#php-session-%e8%8e%b7%e5%8f%96%e4%b8%8d%e5%88%b0%e4%b9%8b%e5%89%8d%e8%ae%be%e7%bd%ae%e5%80%bc%e7%9a%84%e9%97%ae%e9%a2%98\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cp\u003e今天帮朋友的服务器部署一个小程序商城时遇到一个 session 无法保存的问题。\u003c/p\u003e","title":"PHP session 获取不到之前设置值的问题"},{"content":"参考 查看日志中访问次数最多的前10个IP #cat access.log | cut -d \u0026#39; \u0026#39; -f 1 | awk \u0026#39;{print $0}\u0026#39; | uniq -c | sort -nr | head -n 100 awk：太强大，一两句说不清楚 uniq -c: 数据去重，-c 的意思是计数（\u0026ndash;count） sort -nr： 排序，-n 按照数字排序(\u0026ndash;numeric-sort)，-r 倒序排序(\u0026ndash;reverse) head -n 100： -n, \u0026ndash;lines=[-]K 当前WEB服务器中联接次数最多的ip地址 #netstat -ntu |awk \u0026#39;{print $5}\u0026#39; |sort | uniq -c| sort -nr 查看日志中出现100次以上的IP，并倒序显示 #cat access.log | cut -d \u0026#39; \u0026#39; -f 1 | awk \u0026#39;{print $0}\u0026#39; | uniq -c | sort -nr | awk \u0026#39;{if ($1 \u0026gt; 10) print $ ","date":"8 February 2017","permalink":"/linux-log-file-statistic-commands/","section":"Posts","summary":"\u003cp\u003e\u003ca href=\"http://xuqq999.blog.51cto.com/3357083/774714\" target=\"_blank\" rel=\"noreferrer\"\u003e参考 \u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"查看日志中访问次数最多的前10个ip\" class=\"relative group\"\u003e查看日志中访问次数最多的前10个IP \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e6%9f%a5%e7%9c%8b%e6%97%a5%e5%bf%97%e4%b8%ad%e8%ae%bf%e9%97%ae%e6%ac%a1%e6%95%b0%e6%9c%80%e5%a4%9a%e7%9a%84%e5%89%8d10%e4%b8%aaip\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecat access.log | cut -d \u0026#39; \u0026#39; -f 1 | awk \u0026#39;{print $0}\u0026#39; | uniq -c | sort -nr | head -n 100\n\u003c/code\u003e\u003c/pre\u003e","title":"Linux 日志分析命令备忘"},{"content":"","date":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"MySQL"},{"content":"近期公司有个业务数据量已经很大了，我们考虑对数据库进行分区。本文做个小纪录\nMySQL 分区功能简介 #在 MySQL 5.1 之前，当一张表数据过多时，数据表的文件过大，严重影响到查询速度时，程序员们会将一张大表根据业务逻辑横向分割为多张表来达到数据在硬盘分开存放的目的。\nMySQL 5.1 后支持的分区功能可以算是 MySQL 官方「分表」的一种解决方案。它的主要优点是业务代码改动极小。\n判断 MySQL 是否开启了分区功能可以使用 show variables like \u0026quot;%part%\u0026quot;; 命令查看：\nmysql\u0026gt; show variables like \u0026#34;%part%\u0026#34;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | have_partitioning | YES | +-------------------+-------+ 1 row in set (0.00 sec) InnoDB 分区问题 #Range 分区是最常见的分区方式\nCREATE TABLE `xxxxx` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `uid` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;用户Id\u0026#39;, `create_time` int(11) unsigned DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, PRIMARY KEY (`id`,`uid`), KEY `uid` (`uid`) ) ENGINE=InnoDB AUTO_INCREMENT=69210 DEFAULT CHARSET=utf8 COMMENT=\u0026#39;支持每日赠送鲜花表\u0026#39; /*!50100 PARTITION BY RANGE (mod(uid,10)) (PARTITION sfg0 VALUES LESS THAN (1) ENGINE = InnoDB, PARTITION sfg1 VALUES LESS THAN (2) ENGINE = InnoDB, PARTITION sfg2 VALUES LESS THAN (3) ENGINE = InnoDB, PARTITION sfg3 VALUES LESS THAN (4) ENGINE = InnoDB, PARTITION sfg4 VALUES LESS THAN (5) ENGINE = InnoDB, PARTITION sfg5 VALUES LESS THAN (6) ENGINE = InnoDB, PARTITION sfg6 VALUES LESS THAN (7) ENGINE = InnoDB, PARTITION sfg7 VALUES LESS THAN (8) ENGINE = InnoDB, PARTITION sfg8 VALUES LESS THAN (9) ENGINE = InnoDB) */ 测试环境使用以上 SQL 建表后，插入数据测试时发现，数据在硬盘上的并不是按照分区来存放的数据文件的，还是存了单个文件。但是将数据表引擎改为 MyISAM 后，是可以正常按照是个文件的分区方式存放数据。这应该和两种引擎的数据结构有关。\n我查看了测试环境 MySQL 的配置文件 innodb_file_per_table 字段发现，测试环境数据库 InnoDB 引擎使用的默认的共享表空间的配置。同一个数据库下所有表数据都存储在 data 目录下 ibdata1 文件中，所以无法对它进行分区。久而久之 ibdata1 这个文件也会越来越大，也不利于数据表中的数据的转移和备份。\n修改数据库配置文件，在 my.cnf 中 [mysqld] 下配置：\ninnodb_file_per_table=1 更改配置后创建一个 名为test的数据库测试分区后的数据是否存在了不同的文件中，如图：\n10 个分区的数据文件的命名方式为表名#分区名.idb。\n通过测试环境测试，没有改任何业务代码，数据库性能得到了一定的提升。可见 MySQL 分区是个低成本的解决方案。\n","date":"8 December 2016","permalink":"/mysql-fen-qu-yu-dao-de-xiao-wen-ti/","section":"Posts","summary":"\u003cp\u003e近期公司有个业务数据量已经很大了，我们考虑对数据库进行分区。本文做个小纪录\u003c/p\u003e","title":"MySQL 分区遇到的小问题"},{"content":"给定的 n 个非负整数表示每个宽度为 1 栅栏的海拔地图的高度，计算在下雨之后能够捕获多少水？\n问题英文描述 #Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining.\n举例：\n给出 [0,1,0,2,1,0,1,3,2,1,2,1], 返回 6。\n这个题目有个最好理解的思路，就是先找到最高点，然后将整个 List 分成两部分去解决。 找到最高点后，采取从两边「爬楼梯」的方式来统计存水的多少，正常的楼梯是不会存水的，因为楼梯都是节节高的。从左右两边开始爬，爬楼的过程中维护当前爬楼的临时最高值。低于这个临时最高值的一楼肯定会存水，这时很容易就能计算出存水量。\n算法的时间复杂度O(n)\nPython 都快忘了，顺便练习一下。下面是 Python 实现：\nclass Solution(object): def trap(self, height): \u0026#34;\u0026#34;\u0026#34; :type height: List[int] :rtype: int \u0026#34;\u0026#34;\u0026#34; # 找到最大值 max_index = height.index(max(height)) height_len = len(height) # 初始化左边当前最大值 current_max = 0; # 初始化总存水量 total = 0 # 爬左楼 for i in range(max_index): if height[i] \u0026gt; current_max: # 维护当前最大值 current_max = height[i] else: # 累计存水量 total += current_max - height[i] # 初始化左边当前最大值 current_max = height[height_len - 1]; # 爬右楼 for i in range(max_index, height_len)[::-1]: if height[i] \u0026gt; current_max: current_max = height[i] else: total += current_max - height[i] print total height_list = [0,1,0,2,1,0,1,3,2,1,2,1] solution = Solution() solution.trap(height_list) ","date":"23 February 2016","permalink":"/trapping-rain-water/","section":"Posts","summary":"\u003cp\u003e给定的 n 个非负整数表示每个宽度为 1 栅栏的海拔地图的高度，计算在下雨之后能够捕获多少水？\u003c/p\u003e\n\u003cp\u003e\n\n\n\n\n\n\n  \n  \n\u003cfigure\u003e\u003cimg src=\"http://www.leetcode.com/static/images/problemset/rainwatertrap.png\" alt=\"示例图\" class=\"mx-auto my-0 rounded-md\" /\u003e\n\u003c/figure\u003e\n\u003c/p\u003e","title":"【LeetCode】42.Trapping Rain Water 问题"},{"content":"","date":null,"permalink":"/tags/leetcode/","section":"Tags","summary":"","title":"LeetCode"},{"content":"最近在学习一些常用的经典算法，比较经典的一个问题就是给定一个序列，求连续子列的最大和。\n用数学语言描述如下：\n给定序列\n[-2,1,-3,4,-1,2,1,-5,4]\n计算出： $$max([0,\u0026hellip;, \\sum A_k])$$\nLeetCode 链接 Maximum Subarray\n这个问题使用在线最优化求解(Online Optimization)算法是效率最高的,只需要维护两个变量，一次循环就可以完成。\nclass Solution(object): def maxSubArray(self, nums): \u0026#34;\u0026#34;\u0026#34; :type nums: List[int] :rtype: int \u0026#34;\u0026#34;\u0026#34; max_sum = nums[0] current_sum = 0 for num in nums: current_sum += num if current_sum \u0026gt; max_sum: max_sum = current_sum if current_sum \u0026lt; 0: current_sum = 0; # 不可能使后面的和增大，抛弃 return max_sum 下面是运行结果： 可见这是执行效率比较高的解法，时间复杂度为O(n)，但是 LeetCode 还推荐去练习另一种分而治之的解决办法，应该是类似二分法。有时间再去实现下。\n","date":"14 February 2016","permalink":"/53-maximum-subarray/","section":"Posts","summary":"\u003cp\u003e最近在学习一些常用的经典算法，比较经典的一个问题就是给定一个序列，求连续子列的最大和。\u003c/p\u003e\n\u003cp\u003e用数学语言描述如下：\u003c/p\u003e\n\u003cp\u003e给定序列\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e[-2,1,-3,4,-1,2,1,-5,4]\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e计算出： $$max([0,\u0026hellip;, \\sum A_k])$$\u003c/p\u003e","title":"【LeetCode】最大子列和问题（53 Maximum Subarray）"},{"content":"问题描述 #员工表包含所有员工。每个员工都有一个ID，并且还有一列表示部门ID。\n部门表包括公司所有的部门。\n写一条 SQL 查询出每个部门薪酬排名前三的的员工。对于上述表，你的 SQL 应该返回下面几列。\nLeetCode链接：Department Top Three Salaries\n员工表 #+----+-------+--------+--------------+ | Id | Name | Salary | DepartmentId | +----+-------+--------+--------------+ | 1 | Joe | 70000 | 1 | | 2 | Henry | 80000 | 2 | | 3 | Sam | 60000 | 2 | | 4 | Max | 90000 | 1 | | 5 | Janet | 69000 | 1 | | 6 | Randy | 85000 | 1 | +----+-------+--------+--------------+ 部门表 #+----+----------+ | Id | Name | +----+----------+ | 1 | IT | | 2 | Sales | +----+----------+ 关系表 #+------------+----------+--------+ | Department | Employee | Salary | +------------+----------+--------+ | IT | Max | 90000 | | IT | Randy | 85000 | | IT | Joe | 70000 | | Sales | Henry | 80000 | | Sales | Sam | 60000 | +------------+----------+--------+ 解决方案 #select d.Name Department, e.Name Employee, e.Salary from Employee e join Department d on d.Id=e.DepartmentId where ( select count(distinct Salary) from Employee where Salary \u0026gt; e.Salary and DepartmentId=d.id ) \u0026lt; 3 order by d.Name, e.Salary desc; ","date":"12 December 2015","permalink":"/leetcode-sql-tong-ji-bu-men-qian-san-ming-gong-zi-185-department-top-three-salaries/","section":"Posts","summary":"\u003ch3 id=\"问题描述\" class=\"relative group\"\u003e问题描述 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%97%ae%e9%a2%98%e6%8f%8f%e8%bf%b0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cp\u003e员工表包含所有员工。每个员工都有一个ID，并且还有一列表示部门ID。\u003c/p\u003e\n\u003cp\u003e部门表包括公司所有的部门。\u003c/p\u003e\n\u003cp\u003e写一条 SQL 查询出每个部门薪酬排名前三的的员工。对于上述表，你的 SQL 应该返回下面几列。\u003c/p\u003e\n\u003cp\u003eLeetCode链接：\u003ca href=\"https://leetcode.com/problems/department-top-three-salaries/\" target=\"_blank\" rel=\"noreferrer\"\u003eDepartment Top Three Salaries\u003c/a\u003e\u003c/p\u003e","title":"【LeetCode】SQL 统计部门前三名工资185. Department Top Three Salaries"},{"content":"最近在多个虚拟机上做主从分离的实验，遇到的小问题，记录一下。\n开启 binlog 日志 #修改 my.cnf 后 MySQL 无法启动，修改内容如下：\nlog-bin=mysql-bin 后来通过搜索相关资料发现 MySQL 5.7 以后开启binlog 日志需要配置 server-id。\n参见 官方文档：\nIn MySQL 5.7.2 and earlier, if you start a master server without using \u0026ndash;server-id to set its ID, the default ID is 0. In this case, the master refuses connections from all slaves, slaves refuse to connect to the master, and the server sets the server_id system variable to 1. In MySQL 5.7.3 and later, the \u0026ndash;server-id must be used if binary logging is enabled, and a value of 0 is not changed by the server. If you specify \u0026ndash;server-id without an argument, the effect is the same as using 0. In either case, if the server_id is 0, binary logging takes place, but slaves cannot connect to the master, nor can any other servers connect to it as slaves. (Bug #11763963, Bug #56718)\nSlave_IO_Running: Connecting 问题 #主服务器配置：\ngrant replication slave on *.* to \u0026#39;slave\u0026#39;@\u0026#39;192.168.206.191\u0026#39; identifie by \u0026#39;XXX\u0026#39;; mysql\u0026gt; show master status; +-------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-------------------+----------+--------------+------------------+-------------------+ | master-bin.000003 | 882 | | | | +-------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 从服务器配置：\nchange master to master_host=\u0026#39;192.168.10.130\u0026#39;, master_user=\u0026#39;xxx\u0026#39;, master_password=\u0026#39;password\u0026#39;, master_log_file=\u0026#39;mysql-bin.000005\u0026#39;, master_log_pos=261; 运行 show slave status 发现 Slave_IO_Running 一栏显示 Connecting。这种问题一般考虑以下几个问题：\nmaster、slave 一些配置信息，尤其注意 master_log_file、master_log_pos\n网络、防火墙、selinux 问题\nmaster、slave 服务器 server-id 需要不一致\nMySQL 的 server UUID #这个问题比较少见，多见于主从服务器使用的同一个系统快照时。\nshow slave status 会提示报错信息：\nLast_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server UUIDs; these UUIDs must be different for replication to work.\nMySQL 的 datadir 下 有个auto.cnf 文件，这个文件记录了 MySQL 服务器的UUID。\nMySQL 的 data 目录可以使用 show variables like \u0026quot;%dir%\u0026quot;; 查看。\nMySQL 的可以把其中一台服务器的auto.cnf 删除，重启 MySQL 服务器后会再次生成新的不重复的 UUID 文件。\n","date":"18 November 2015","permalink":"/mysql-zhu-cong-fen-chi-pei-zhi-de-yi-xie-keng/","section":"Posts","summary":"\u003cp\u003e最近在多个虚拟机上做主从分离的实验，遇到的小问题，记录一下。\u003c/p\u003e","title":"MySQL 主从分离配置的一些坑"},{"content":"今天安装了一台 Centos 6.8 minimal 做测试使用，安装后，默认网卡是没有开机启动的。使用的是桥接模式，这种模式是通过宿主机的虚拟路由器将宿主机和虚拟机连接到一起。\n首先改下配置 eth-0 的配置\nvi /etc/sysconfig/network-scripts/ifcfg-eth0：\n... ONBOOT=yes ... 手动重启网络 services network restart\n现在还是 ping 不同外网，还需要改一下 DNS 的配置：\nvi /etc/resolv.conf\n... nameserver 8.8.8.8 # 或者 114.114.114.114 保存后在重启下网络，现在发现可以 PING 通外网了。\n如果需要手动配置静态IP。可以使用如下配置：\n... BOOTPROTO=\u0026#34;static\u0026#34; IPADDR=192.168.0.103 NETMASK=255.255.255.0 GATEWAY=192.168.0.1 BROADCAST=192.168.0.255 DNS1=114.114.114.114 修改配置后重启后生效。\n如果需要使用 ssh 登录，有时候还需要禁用下 IPV6，否则可能出现 ssh 无法连接的情况。\n","date":"8 October 2015","permalink":"/virtualbox-centos-minimal-network-config-and-ssh-login/","section":"Posts","summary":"\u003cp\u003e今天安装了一台 Centos 6.8 minimal 做测试使用，安装后，默认网卡是没有开机启动的。使用的是桥接模式，这种模式是通过宿主机的虚拟路由器将宿主机和虚拟机连接到一起。\u003c/p\u003e","title":"VirtualBox CentOS（minimal）配置网络访问外网支持并 SSH"},{"content":"前几天买了个 VPS，因为之前接触 Nginx 不是很多，所以折腾 LNMP环境折腾了几个小时，所以我想重新安装一遍并写篇学习笔记，或者说教程，因此本文将从在崭新的 Centos 上搭建 LNMP 环境，为了所有软件都可以选择指定版本和安装配置，因此除了依赖包之外都采用源码包安装的方式来安装。废话不多说，刚刚把 VPS rebulid。\n注：本文属于新手友好型，能遇到的错误基本上都会遇到。😄\n一、安装 Nginx #这里我选择的是1.8.0 执行命令下载并解压 Nginx 源码包\nwget http://nginx.org/download/nginx-1.8.0.tar.gz tar -xzvf nginx-1.8.0.tar.gz cd nginx-1.8.0 这里我们./Configure 肯定会报错的，因为我们这是一台崭新的 Centos 系统，缺少好多Nginx依赖包，这里我直接 ./configure 先试一下有什么错误\n./configure: error: C compiler cc is not found\n好吧，甚至连 gcc 都没有，先安装 gcc 才能编译源码\nyum install gcc 下面正式编译\n./configure --prefix=/usr --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx/nginx.pid --lock-path=/var/lock/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_flv_module --with-http_stub_status_module --with-http_gzip_static_module --http-client-body-temp-path=/var/tmp/nginx/client/ --http-proxy-temp-path=/var/tmp/nginx/proxy/ --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi --http-scgi-temp-path=/var/tmp/nginx/scgi --with-pcre 又一个错误来了\n./configure: error: the HTTP rewrite module requires the PCRE library. You can either disable the module by using \u0026ndash;without-http_rewrite_module option, or install the PCRE library into the system, or build the PCRE library statically from the source with nginx by using \u0026ndash;with-pcre= option.\n这个错误我们看提示可以看出，Nginx 需要安装 PCRE Library，类似的错误提示还有很多，下面我们一次性将 Nginx 的依赖包都安装上\n//安装PCRE 库是为使用 Nginx 支持 HTTP Rewrite 模块。 yum -y install pcre-devel // zlib yum -y install zlib-devel // openssl yum -y install openssl-devel 再执行上面的 ./configure 命令，当出现下面提示时，说明我们已经配置好了可以编译了 因为我们配置时定义了 user 和 group，下面新建一个nginx 用户和nginx 用户组才能运行nginx服务进程\n# groupadd -r nginx # useradd -r -g nginx -s /bin/false -M nginx # id nginx Configuration summary\nusing system PCRE library using system OpenSSL library md5: using OpenSSL library sha1: using OpenSSL library using system zlib library \u0026hellip;\u0026hellip; make //一般 make test 可省略 make test make install 安装成功后我们还需要做一些配置\n1、为Nginx提供sysv风格的服务脚本（ Red Hat Nginx Init Script Should work on RHEL, Fedora, CentOS. Tested on CentOS 5. Save this file as /etc/init.d/nginx ）\n在新建文件\nvi /etc/rc.d/init.d/nginx 内容如下：\n#!/bin/sh # # nginx - this script starts and stops the nginx daemon # # chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \\ # proxy and IMAP/POP3 proxy server # processname: nginx # config: /etc/nginx/nginx.conf # config: /etc/sysconfig/nginx # pidfile: /var/run/nginx.pid # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ \u0026#34;$NETWORKING\u0026#34; = \u0026#34;no\u0026#34; ] \u0026amp;\u0026amp; exit 0 nginx=\u0026#34;/usr/sbin/nginx\u0026#34; prog=$(basename $nginx) NGINX_CONF_FILE=\u0026#34;/etc/nginx/nginx.conf\u0026#34; [ -f /etc/sysconfig/nginx ] \u0026amp;\u0026amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx make_dirs() { # make required directories user=`nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#34;configure arguments:\u0026#34; | sed \u0026#39;s/[^*]*--user=\\([^ ]*\\).*/\\1/g\u0026#39; -` options=`$nginx -V 2\u0026gt;\u0026amp;1 | grep \u0026#39;configure arguments:\u0026#39;` for opt in $options; do if [ `echo $opt | grep \u0026#39;.*-temp-path\u0026#39;` ]; then value=`echo $opt | cut -d \u0026#34;=\u0026#34; -f 2` if [ ! -d \u0026#34;$value\u0026#34; ]; then # echo \u0026#34;creating\u0026#34; $value mkdir -p $value \u0026amp;\u0026amp; chown -R $user $value fi fi done } start() { [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $\u0026#34;Starting $prog: \u0026#34; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; touch $lockfile return $retval } stop() { echo -n $\u0026#34;Stopping $prog: \u0026#34; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] \u0026amp;\u0026amp; rm -f $lockfile return $retval } restart() { configtest || return $? stop sleep 1 start } reload() { configtest || return $? echo -n $\u0026#34;Reloading $prog: \u0026#34; killproc $nginx -HUP RETVAL=$? echo } force_reload() { restart } configtest() { $nginx -t -c $NGINX_CONF_FILE } rh_status() { status $prog } rh_status_q() { rh_status \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 } case \u0026#34;$1\u0026#34; in start) rh_status_q \u0026amp;\u0026amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $\u0026#34;Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}\u0026#34; exit 2 esac 给予刚才的文件可执行权限\nchmod +x /etc/rc.d/init.d/nginx 并把他添加到服务列表中\nchkconfig --add nginx chkconfig nginx on 启动服务，并查看启动状态\n/etc/init.d/nginx start netstat -tnlp | grep nginx 现在在可以访问了，Welcome to nginx!\n重启服务命令\n/etc/init.d/nginx restart /etc/init.d/nginx stop 二、安装 MySQL #下载 MySQL #MySQL 的官方下载地址，进去选择 Source Code 这里我装的是5.6.28 如果你不想再去官网找的话，可以在你的下载目录直接执行\nwget http://cdn.mysql.com//Downloads/MySQL-5.6/mysql-5.6.28.tar.gz tar -xzvf mysql-5.6.28.tar.gz cd mysql-5.6.28 准备工作 #安装前的准备工作，MySQL需要用到的依赖包依次安装上\nyum -y install gcc-c++ yum -y install cmake yum -y install bison-devel yum -y install ncurses-devel 编译安装 #编译配置\ncmake \\ -DCMAKE_INSTALL_PREFIX=/usr/local/mysql \\ -DMYSQL_DATADIR=/usr/local/mysql/data \\ -DSYSCONFDIR=/etc \\ -DWITH_MYISAM_STORAGE_ENGINE=1 \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_MEMORY_STORAGE_ENGINE=1 \\ -DWITH_READLINE=1 \\ -DMYSQL_UNIX_ADDR=/var/lib/mysql/mysql.sock \\ -DMYSQL_TCP_PORT=3306 \\ -DENABLED_LOCAL_INFILE=1 \\ -DWITH_PARTITION_STORAGE_ENGINE=1 \\ -DEXTRA_CHARSETS=all \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci 参数详细配置，参考MySQL官方文档的MySQL Source-Configuration Options 我这里出现了以下警告：\nCMake Warning: Manually-specified variables were not used by the project:\nWITH_MEMORY_STORAGE_ENGINE\nWITH_READLINE\n\u0026ndash; Build files have been written to: /root/lnmp_source/mysql-5.6.28\n提示两个配置项没有应用上，我干脆就把这两项配置去掉了重新./configure 了一下，这次没有警告了 我查了下这两项的作用：\n-WITH_MEMORY_STORAGE_ENGINE #支持Memory引擎 -DWITH_READLINE=1 \\ #快捷键功能\n如果用到再做配置，下面安装\n好了开始编译\nmake MySQL 编译时间比较长\u0026hellip;我这单核 VPS\u0026hellip;30分钟后\u0026hellip;\nmake install 创建 MySQL 的用户和用户组\ngroupadd mysql useradd -g mysql mysql 修改/usr/local/mysql权限\nchown -R mysql:mysql /usr/local/mysql 初始化配置 #进入安装路径\ncd /usr/local/mysql 进入安装路径，执行初始化配置脚本，创建系统自带的数据库和表\nscripts/mysql_install_db --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --user=mysql 这里执行会报错，如下：\n./scripts/mysql_install_db: /usr/bin/perl: bad interpreter: No such file or directory 原因是系统没有安装Perl 和 Perl-devel\n解决办法，执行：\nyum -y install perl perl-devel 安装完成后再执行 MySQL 初始化脚本就可以了 现在应该可以开启 MySQL 了。\n同样将 MySQL 提供的sysv风格的服务脚本复制到 /etc/init.d/mysql目录\ncp support-files/mysql.server /etc/init.d/mysql // 设置开机启动 chkconfig mysql on // 启动服务 service mysql start // 启动MySQL // 或者使用 /etc/init.d/mysql start // 启动 MySQL 将 MySQL 加入环境变量，修改/etc/profile文件，在文件末尾添加\nPATH=/usr/local/mysql/bin:$PATH export PATH 保存并关闭文件，运行下面的命令让配置生效\nsource /etc/profile MySQL 跑起来了，我极低配 512 内存的 VPS 瞬间被占用了 400MB 啊 修改 /usr/local/mysql/my.cnf 中的以下几项配置（没有该项可以添加）：\ntable_definition_cache=400 table_open_cache=256 然后\n/etc/init.d/mysql restart 瞬间清爽了，只能牺牲性能了😂。\n修改 MySQL root 账户密码 #mysql -uroot mysql\u0026gt; SET PASSWORD = PASSWORD(\u0026#39;YOUR PASSWORD\u0026#39;); 修改防火墙配置 #打开/etc/sysconfig/iptables\n在“-A INPUT –m state \u0026ndash;state NEW –m tcp –p –dport 22 –j ACCEPT”，下添加：\n-A INPUT -m state --state NEW -m tcp -p -dport 3306 -j ACCEPT 然后保存，并关闭该文件，在终端内运行下面的命令，刷新防火墙配置：\nservice iptables restart MySQL 安装完毕。\n安装 PHP7 #下载 PHP7源码包 #我这里下载的是 PHP 7，下载别的版本去php.net\nwget http://cn2.php.net/distributions/php-7.0.2.tar.gz tar -xzvf php-7.0.2.tar.gz cd php-7.0.2 编译配置 #如果我们直接配置的话应该会报错，我们还需要安装一些 PHP 的依赖包，编译配置一下试试\n./configure --enable-fpm --with-mysql 首先报以下错误：\nconfigure: error: xml2-config not found. Please check your libxml2 installation.\n缺少 libxml2，直接使用 yum 方式安装 libxml2\nyum install -y libxml2 下面一口气把所有的PHP 用到的软件包都安装上\nyum install -y libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers php-mysqlnd libmcrypt-devel libtidy libtidy-devel recode recode-devel libxpm-devel 安装完之后可以编译配置了\n./configure --prefix=/usr/local/php7 --with-config-file-path=/etc/php7 --with-mysql=mysqlnd --with-pdo-mysql=mysqlnd --with-mysqli=mysqlnd --with-gd --with-iconv --with-zlib --enable-xml --enable-bcmath --enable-shmop --enable-sysvsem --enable-inline-optimization --enable-mbregex --enable-fpm --enable-mbstring --enable-ftp --enable-gd-native-ttf --with-openssl --enable-pcntl --enable-sockets --with-xmlrpc --enable-zip --enable-soap --without-pear --with-gettext --enable-session --with-mcrypt --with-curl --with-jpeg-dir --with-freetype-dir --with-xpm-dir=/usr --with-bz2 注意前两个配置\n--prefix=/usr/local/php7 //安装位置 --with-config-file-path=/etc/php7 //配置文件位置 如果还会报错，可能是缺少依赖包，按照提示安装就可以了。\nconfigure: error: xpm.h not found.\n上面忘了安装 libxpm 和 mcrypt 扩展 安装 libXpm\nyum install libXpm-devel 好多 yum 源中没有 mcrypt，担心第三方源不可靠，我选择使用源码安装 mcrypt，切换到另一个目录\nwget ftp://mcrypt.hellug.gr/pub/crypto/mcrypt/libmcrypt/libmcrypt-2.5.6.tar.gz tar -zxvf libmcrypt-2.5.6.tar.gz cd libmcrypt-2.5.6.tar. make \u0026amp;\u0026amp; make install 再配置，编译安装\nmake sudo make install 这里列出 PHP 编译配置常见错误和解决办法：\nconfigure: error: xslt-config not found. Please reinstall the libxslt \u0026gt;= 1.1.0 distribution\nyum install libxslt-devel configure: error: Could not find net-snmp-config binary. Please check your net-snmp installation.\nyum install net-snmp-devel configure: error: Please reinstall readline - I cannot find readline.h\nyum install readline-devel configure: error: Cannot find pspell\nyum install aspell-devel checking for unixODBC support\u0026hellip; configure: error: ODBC header file \u0026lsquo;/usr/include/sqlext.h\u0026rsquo; not found!\nyum install unixODBC-devel configure: error: Unable to detect ICU prefix or /usr/bin/icu-config failed. Please verify ICU install prefix and make sure icu-config works.\nyum install libicu-devel configure: error: utf8mime2text() has new signature, but U8TCANONICAL is missing. This should not happen. Check config.log for additional information.\nyum install libc-client-devel configure: error: freetype.h not found.\nyum install freetype-devel configure: error: xpm.h not found.\nyum install libXpm-devel configure: error: png.h not found.\nyum install libpng-devel configure: error: vpx_codec.h not found.\nyum install libvpx-devel configure: error: Cannot find enchant\nyum install enchant-devel configure: error: Please reinstall the libcurl distribution - easy.h should be in /include/curl/\n配置 Nginx #nginx本身不能处理PHP，它只是个web服务器，当接收到请求后，如果是php请求，则发给php解释器处理，并把结果返回给客户端。\nnginx一般是把请求发fastcgi管理进程处理，fascgi管理进程选择cgi子进程处理结果并返回被nginx\n首先修改 Nginx 的配置，刚才安装时配置的配置文件目录是 /etc/nginx/nginx.conf\nvi /etc/nginx/nginx.conf # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ .php$ { root /var/www; //根目录 root\tfastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 这里需要注意 location ~.php 的配置块的 root 根目录一定要跟 server 块的配置一样，否则 php 文件会不能解析，会报 File not found 错误。\n同时也建议在location / 配置下的 index 加上 index.php\n配置好 Nginx 可以先尝试启动 php-fpm\n/usr/local/php7/sbin/php-fpm 嗯，是的，应该会报下面的错误😄\nERROR: failed to open configuration file \u0026lsquo;/local/php7/etc/php-fpm.conf\u0026rsquo;: No such file or directory (2) [20-Jan-2016 10:56:50] ERROR: failed to load configuration file \u0026lsquo;/local/php7/etc/php-fpm.conf\u0026rsquo;\n将默认的配置文件 cp 为正房\ncp /local/php7/etc/php-fpm.conf.default /local/php7/etc/php-fpm.conf 如果这时候启动 php-fpm 会报下面的错误\nWARNING: Nothing matches the include pattern \u0026lsquo;/local/php7/etc/php-fpm.d/*.conf\u0026rsquo; from /local/php7/etc/php-fpm.conf at line 125. [20-Jan-2016 11:03:40] ERROR: No pool defined. at least one pool section must be specified in config file\n根据错误提示信息，还是初始化配置文件\ncp /local/php7/etc/php-fpm.d/www.conf.default /local/php7/etc/php-fpm.d/www.conf 这时候应该可以启动了。 下面测试一下\ncd /var/www echo \u0026#34;\u0026lt;?php phpinfo();\u0026#34; \u0026gt; index.php 到此为止，整个安装过程就写完了.\n零零散散地看了网上很多的教程，所以决定总（fu）结（zhi）一（yi）下（fen），描述比较傻瓜化，安装过程中基本所有的错误就提到了。希望能对刚踏入 Linux 服务端的同学有所帮助。\n参考文章：\nNginx 源码编译安装 CentOS 6.4下编译安装MySQL 5.6.14 编译安装PHP7 beta1 PHP configuration error and Solutions in RPM ","date":"15 September 2015","permalink":"/new-centos-compiled-install-lnmp-environment/","section":"Posts","summary":"\u003cp\u003e前几天买了个 VPS，因为之前接触 Nginx 不是很多，所以折腾 LNMP环境折腾了几个小时，所以我想重新安装一遍并写篇学习笔记，或者说教程，因此本文将从在崭新的 Centos 上搭建 LNMP 环境，为了所有软件都可以选择指定版本和安装配置，因此除了依赖包之外都采用源码包安装的方式来安装。废话不多说，刚刚把 VPS rebulid。\u003c/p\u003e","title":"Centos上从零开始编译安装LNMP环境"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]